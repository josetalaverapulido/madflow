# madflow

## Project Structure

- `dags/`  
  Contains Airflow DAGs (workflows) for orchestrating data pipelines.

- `logs/`  
  Stores execution logs generated by Airflow.

- `config/`  
  Custom configuration files for Airflow (e.g., `airflow.cfg`).

- `scraper/`  
  Web scraping code and related modules.

- `spark_jobs/`  
  PySpark scripts for data processing and querying.

- `streamlit_app/`  
  Streamlit application for data visualization.

- `utils/`  
  Utility functions and helper scripts.

- `data/`  
  Project datasets.
  - `raw/` - Raw, unprocessed data.
  - `processed/` - Cleaned and processed data.

- `requirements.txt`  
  Python dependencies for the project.

- `docker-compose.yaml`  
  Docker Compose configuration for running Airflow and related services.

- `README.md`  
  Project documentation.
